{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.train.data.x\n",
      "   train_y_fn=/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:37 2018: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 30 trees and 100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 60 trees and 200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 90 trees and 300 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 120 trees and 401 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 149 trees and 500 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 179 trees and 600 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 209 trees and 700 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 239 trees and 800 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 268 trees and 900 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 298 trees and 1000 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 328 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 357 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 387 trees and 1301 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:37 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 417 trees and 1401 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-01\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-02\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-03\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-04\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-05\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-06\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-07\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-08\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-09\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-10\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-11\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-12\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-13\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-14\n",
      "\n",
      "Sat Apr 14 06:32:37 2018: Done ... \n",
      "elapsed: 0.097507\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.train.data.x\n",
      "   train_y_fn=/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:37 2018: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 37 trees and 101 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 76 trees and 200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 116 trees and 301 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 155 trees and 400 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 196 trees and 500 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 237 trees and 600 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 277 trees and 701 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 318 trees and 801 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 358 trees and 900 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 398 trees and 1000 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 437 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 477 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 517 trees and 1300 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:37 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 557 trees and 1400 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-01\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-02\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-03\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-04\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-05\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-06\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-07\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-08\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-09\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-10\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-11\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-12\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-13\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-14\n",
      "\n",
      "Sat Apr 14 06:32:37 2018: Done ... \n",
      "elapsed: 0.11389\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.train.data.x\n",
      "   train_y_fn=/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:37 2018: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 50 trees and 100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 100 trees and 200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 150 trees and 300 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 200 trees and 400 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 250 trees and 500 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 300 trees and 600 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 350 trees and 700 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 400 trees and 800 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 450 trees and 900 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 500 trees and 1000 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 550 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 600 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 650 trees and 1300 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:37 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 700 trees and 1400 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-01\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-02\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-03\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-04\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-05\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-06\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-07\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-08\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-09\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-10\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-11\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-12\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-13\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-14\n",
      "\n",
      "Sat Apr 14 06:32:37 2018: Done ... \n",
      "elapsed: 0.14046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-14\n",
      "   test_x_fn=/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.test.data.x\n",
      "   prediction_fn=/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:37 2018: Predicting ... \n",
      "elapsed: 0.000604\n",
      "/tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.predictions.txt: /tmp/rgf/952c58d6-ad8f-4cd9-99d5-12fc21e25aee118.model-14,#leaf=1400,#tree=700\n",
      "Sat Apr 14 06:32:37 2018: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-14\n",
      "   test_x_fn=/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.test.data.x\n",
      "   prediction_fn=/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:37 2018: Predicting ... \n",
      "elapsed: 0.000662\n",
      "/tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.predictions.txt: /tmp/rgf/93b693a6-3add-4152-81e8-256b6fe3f712119.model-14,#leaf=1401,#tree=417\n",
      "Sat Apr 14 06:32:37 2018: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-14\n",
      "   test_x_fn=/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.test.data.x\n",
      "   prediction_fn=/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:37 2018: Predicting ... \n",
      "elapsed: 0.000694\n",
      "/tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.predictions.txt: /tmp/rgf/81f7aa22-0e84-44df-a30d-b6b78ac9c063120.model-14,#leaf=1400,#tree=557\n",
      "Sat Apr 14 06:32:37 2018: Done ... \n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.train.data.x\n",
      "   train_y_fn=/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:37 2018: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 27 trees and 101 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 54 trees and 201 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 81 trees and 300 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 108 trees and 400 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 134 trees and 500 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 161 trees and 600 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 188 trees and 701 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 214 trees and 801 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 241 trees and 901 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 267 trees and 1001 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 293 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 320 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 347 trees and 1301 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:37 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 373 trees and 1400 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-01\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-02\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-03\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-04\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-05\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-06\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-07\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-08\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-09\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-10\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-11\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-12\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-13\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-14\n",
      "\n",
      "Sat Apr 14 06:32:37 2018: Done ... \n",
      "elapsed: 0.087365\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.train.data.x\n",
      "   train_y_fn=/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:37 2018: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 40 trees and 100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 80 trees and 201 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 119 trees and 301 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 158 trees and 401 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 195 trees and 500 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 233 trees and 600 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 271 trees and 700 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 309 trees and 800 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 346 trees and 900 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 384 trees and 1001 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 422 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 459 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 496 trees and 1301 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:38 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 533 trees and 1401 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-01\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-02\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-03\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-04\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-05\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-06\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-07\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-08\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-09\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-10\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-11\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-12\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-13\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-14\n",
      "\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "elapsed: 0.11526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.train.data.x\n",
      "   train_y_fn=/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:37 2018: Start ... #train=99\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x99, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 50 trees and 100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 100 trees and 200 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 150 trees and 300 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 200 trees and 400 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 250 trees and 500 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 300 trees and 600 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 350 trees and 700 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 400 trees and 800 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 450 trees and 900 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 500 trees and 1000 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 550 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:37 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:37 2018: Calling optimizer with 600 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 650 trees and 1300 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:38 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 700 trees and 1400 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-01\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-02\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-03\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-04\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-05\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-06\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-07\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-08\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-09\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-10\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-11\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-12\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-13\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-14\n",
      "\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "elapsed: 0.13855\n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-14\n",
      "   test_x_fn=/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.test.data.x\n",
      "   prediction_fn=/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:38 2018: Predicting ... \n",
      "elapsed: 0.000601\n",
      "/tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.predictions.txt: /tmp/rgf/e7a0affd-8d64-4f1c-a107-09540481e0b7121.model-14,#leaf=1400,#tree=700\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-14\n",
      "   test_x_fn=/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.test.data.x\n",
      "   prediction_fn=/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:38 2018: Predicting ... \n",
      "elapsed: 0.000675\n",
      "/tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.predictions.txt: /tmp/rgf/5fd70e92-d9dc-4738-8997-a593d62f7138122.model-14,#leaf=1400,#tree=373\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-14\n",
      "   test_x_fn=/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.test.data.x\n",
      "   prediction_fn=/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:38 2018: Predicting ... \n",
      "elapsed: 0.000736\n",
      "/tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.predictions.txt: /tmp/rgf/8c81c7d6-c436-4471-8b0c-e036fc768101123.model-14,#leaf=1401,#tree=533\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.train.data.x\n",
      "   train_y_fn=/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:38 2018: Start ... #train=102\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x102, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 32 trees and 100 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 64 trees and 200 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 95 trees and 300 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 127 trees and 401 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 158 trees and 500 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 190 trees and 601 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 222 trees and 700 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 255 trees and 801 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 287 trees and 900 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 319 trees and 1000 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 351 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 384 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 417 trees and 1300 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:38 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 449 trees and 1400 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-01\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-02\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-03\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-04\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-05\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-06\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-07\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-08\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-09\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-10\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-11\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-12\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-13\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-14\n",
      "\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "elapsed: 0.1042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.train.data.x\n",
      "   train_y_fn=/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:38 2018: Start ... #train=102\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x102, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 44 trees and 100 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 88 trees and 200 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 133 trees and 300 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 177 trees and 400 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 221 trees and 500 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 265 trees and 601 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 308 trees and 700 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 352 trees and 800 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 396 trees and 900 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 440 trees and 1000 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 483 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 526 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 569 trees and 1300 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:38 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 613 trees and 1400 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-01\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-02\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-03\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-04\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-05\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-06\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-07\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-08\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-09\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-10\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-11\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-12\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-13\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-14\n",
      "\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "elapsed: 0.13024\n",
      "\n",
      "None\n",
      "\"train\": \n",
      "   algorithm=RGF\n",
      "   train_x_fn=/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.train.data.x\n",
      "   train_y_fn=/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.train.data.y\n",
      "   Log:ON\n",
      "   model_fn_prefix=/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading training data ... \n",
      "Sat Apr 14 06:32:38 2018: Start ... #train=102\n",
      "--------------------\n",
      "Forest-level: \n",
      "   loss=Log\n",
      "   max_leaf_forest=1400\n",
      "   max_tree=700\n",
      "   opt_interval=100\n",
      "   test_interval=100\n",
      "   num_tree_search=1\n",
      "   Verbose:ON\n",
      "   memory_policy=Generous\n",
      "-------------\n",
      "Training data: 4x102, nonzero_ratio=1; managed as dense data.\n",
      "-------------\n",
      "Optimization: \n",
      "   loss=Log\n",
      "   num_iteration_opt=7\n",
      "   reg_L2=0.2\n",
      "   opt_stepsize=0.7\n",
      "   max_delta=1\n",
      "Tree-level: min_pop=8\n",
      "Node split: reg_L2=0.07\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 50 trees and 100 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=1\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 100 trees and 200 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=2\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 150 trees and 300 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=3\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 200 trees and 400 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=4\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 250 trees and 500 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=5\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 300 trees and 600 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=6\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 350 trees and 700 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=7\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 400 trees and 800 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=8\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 450 trees and 900 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=9\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 500 trees and 1000 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=10\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 550 trees and 1100 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=11\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 600 trees and 1200 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=12\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 650 trees and 1300 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=13\n",
      "Sat Apr 14 06:32:38 2018: AzRgforest: #leaf reached max\n",
      "Sat Apr 14 06:32:38 2018: Calling optimizer with 700 trees and 1400 leaves\n",
      "Sat Apr 14 06:32:38 2018: Writing model: seq#=14\n",
      "\n",
      "Generated 14 model file(s): \n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-01\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-02\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-03\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-04\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-05\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-06\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-07\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-08\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-09\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-10\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-11\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-12\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-13\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-14\n",
      "\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "elapsed: 0.14048\n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-14\n",
      "   test_x_fn=/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.test.data.x\n",
      "   prediction_fn=/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:38 2018: Predicting ... \n",
      "elapsed: 0.000602\n",
      "/tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.predictions.txt: /tmp/rgf/7d6e466f-58fa-43bd-9e7e-dba86c0df157124.model-14,#leaf=1400,#tree=700\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-14\n",
      "   test_x_fn=/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.test.data.x\n",
      "   prediction_fn=/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:38 2018: Predicting ... \n",
      "elapsed: 0.000698\n",
      "/tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.predictions.txt: /tmp/rgf/76a4941c-02c3-4c66-9531-31e9b117eaf3125.model-14,#leaf=1400,#tree=449\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "\n",
      "None\n",
      "\"predict\": \n",
      "   model_fn=/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-14\n",
      "   test_x_fn=/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.test.data.x\n",
      "   prediction_fn=/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.predictions.txt\n",
      "   Log:ON\n",
      "--------------------\n",
      "Sat Apr 14 06:32:38 2018: Reading test data ... \n",
      "Sat Apr 14 06:32:38 2018: Predicting ... \n",
      "elapsed: 0.000713\n",
      "/tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.predictions.txt: /tmp/rgf/bedebed5-8db4-412b-bc15-3985709a2b01126.model-14,#leaf=1400,#tree=613\n",
      "Sat Apr 14 06:32:38 2018: Done ... \n",
      "\n",
      "None\n",
      "RGF Classfier score: 0.95997\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from rgf.sklearn import RGFClassifier\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "rng = check_random_state(0)\n",
    "perm = rng.permutation(iris.target.size)\n",
    "iris.data = iris.data[perm]\n",
    "iris.target = iris.target[perm]\n",
    "\n",
    "rgf = RGFClassifier(max_leaf=1400,\n",
    "                    algorithm=\"RGF\",\n",
    "                    test_interval=100,\n",
    "                    loss=\"Log\",\n",
    "                    l2=0.2,\n",
    "                    sl2=0.07,\n",
    "                    n_iter=7,\n",
    "                    n_tree_search=1,\n",
    "                    min_samples_leaf=8,\n",
    "                    learning_rate=0.7,\n",
    "                    verbose=True)\n",
    "\n",
    "n_folds = 3\n",
    "\n",
    "rgf_scores = cross_val_score(rgf,\n",
    "                             iris.data,\n",
    "                             iris.target,\n",
    "                             cv=StratifiedKFold(n_folds))\n",
    "\n",
    "rgf_score = sum(rgf_scores)/n_folds\n",
    "print('RGF Classfier score: {0:.5f}'.format(rgf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'Iris Plants Database\\n====================\\n\\nNotes\\n-----\\nData Set Characteristics:\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20  0.76     0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML iris datasets.\\nhttp://archive.ics.uci.edu/ml/datasets/Iris\\n\\nThe famous Iris database, first used by Sir R.A Fisher\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\nReferences\\n----------\\n   - Fisher,R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda,R.O., & Hart,P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...\\n',\n",
       " 'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
