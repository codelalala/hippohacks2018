{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.utils.validation import check_random_state\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "#from rgf.sklearn import RGFClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name=['Date','Address','Species','Block','Street','Trap','AddressNumberAndStreet','Latitude','AddressAccuracy','NumMosquitos','WnvPresent']\n",
    "\n",
    "def get_set(filename):\n",
    "    train_set=pd.read_csv(filename, header=0)\n",
    "\n",
    "\n",
    "    train = datasets.load_iris()\n",
    "    train['data'] =np.array([#pd.Categorical(train_set['Species']).codes, \n",
    "       \n",
    "        train_set['NumMosquitos'],\n",
    "        train_set['CULEX ERRATICUS'],\n",
    "        train_set['CULEX PIPIENS'],\n",
    "        train_set['CULEX PIPIENS/RESTUANS'],\n",
    "        train_set['CULEX RESTUANS'],\n",
    "        train_set['CULEX SALINARIUS'],\n",
    "        train_set['CULEX TARSALIS'],\n",
    "        train_set['CULEX TERRITANS'],\n",
    "        \n",
    "        train_set['Tmax'], \n",
    "        train_set['Tmin'], \n",
    "        train_set['Tavg'], \n",
    "        train_set['DewPoint'], \n",
    "        train_set['Heat'], \n",
    "        train_set['Cool'], \n",
    "        train_set['StnPressure'], \n",
    "        train_set['SeaLevel'], \n",
    "        train_set['ResultSpeed'], \n",
    "        train_set['ResultDir'], \n",
    "        train_set['AvgSpeed'], \n",
    "        train_set['Tmax.1'], \n",
    "        train_set['Tmin.1'], \n",
    "        train_set['Tavg.1'], \n",
    "        train_set['DewPoint.1'], \n",
    "        train_set['Heat.1'], \n",
    "        train_set['Cool.1'], \n",
    "        train_set['StnPressure.1'], \n",
    "        train_set['SeaLevel.1'], \n",
    "        train_set['ResultSpeed.1'], \n",
    "        train_set['ResultDir.1'], \n",
    "        train_set['AvgSpeed.1'], \n",
    "        train_set['Latitude'], \n",
    "        train_set['Longitude'], \n",
    "        train_set['AddressAccuracy'], \n",
    "        \n",
    "    \n",
    "                                ]).transpose()\n",
    "\n",
    "    train['DESCR'] = ''\n",
    "    train['feature_names'] = ['Date', 'Latitude', 'Latitude', 'AddressAccuracy', 'NumMosquitos']\n",
    "    train['target'] = np.array(train_set['WnvPresent'])\n",
    "    train['target_names'] = train['target']\n",
    "    return train\n",
    "\n",
    "\n",
    "train = get_set('final_train.csv');\n",
    "\n",
    "rng = check_random_state(0)\n",
    "perm = rng.permutation(train.target.size)\n",
    "test_data = train.data[perm]\n",
    "test_target = train.target[perm]\n",
    "\n",
    "\n",
    "rgf = GradientBoostingClassifier(loss='deviance', \n",
    "                                 learning_rate=0.0035, \n",
    "                                 n_estimators=1000, \n",
    "                                 subsample=1.0, \n",
    "                                 criterion='friedman_mse', \n",
    "                                 min_samples_split=2, \n",
    "                                 min_samples_leaf=1, \n",
    "                                 min_weight_fraction_leaf=0.0, \n",
    "                                 max_depth=7, \n",
    "                                 min_impurity_decrease=0.0, \n",
    "                                 min_impurity_split=None, \n",
    "                                 init=None, random_state=None, \n",
    "                                 max_features=None, \n",
    "                                 verbose=0, \n",
    "                                 max_leaf_nodes=None, \n",
    "                                 warm_start=False, \n",
    "                                 presort='auto')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fit = rgf.fit(train.data, train.target)\n",
    "\n",
    "'''rgf_scores = cross_val_score(rgf,\n",
    "                             train.data,\n",
    "                             train.target,\n",
    "                             cv=StratifiedKFold(n_folds))\n",
    "'''\n",
    "#rgf_score = sum(rgf_scores)/n_folds\n",
    "#print('RGF Classfier score: {0:.5f}'.format(rgf_score))\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n",
    "mapdata = np.loadtxt(\"mapdata_copyright_openstreetmap_contributors.txt\")\n",
    "traps = pd.read_csv('train.csv')[['Date', 'Trap','Longitude', 'Latitude', 'WnvPresent']]\n",
    "\n",
    "aspect = mapdata.shape[0] * 1.0 / mapdata.shape[1]\n",
    "lon_lat_box = (-88, -87.5, 41.6, 42.1)\n",
    "\n",
    "plt.figure(figsize=(10,14))\n",
    "plt.imshow(mapdata, \n",
    "           cmap=plt.get_cmap('gray'), \n",
    "           extent=lon_lat_box, \n",
    "           aspect=aspect)\n",
    "\n",
    "\n",
    "prediction = fit.predict(train.data)\n",
    "\n",
    "locations = traps[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "red = np.array([[traps['Longitude'][i], traps['Latitude'][i]]  \n",
    "             for i in range(len(traps['WnvPresent'])) if (prediction[i] == 1)])\n",
    "#red = traps[['Longitude', 'Latitude']].drop_duplicates().values\n",
    "plt.scatter(locations[:,0], locations[:,1], marker='x')\n",
    "plt.scatter(red[:,0], red[:,1], marker='o', alpha = 0.05, c = 'red', s = 1000)\n",
    "plt.savefig('estimation.png')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8494999180193473\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation,metrics\n",
    "from sklearn import svm\n",
    "\n",
    "train_x,test_x,train_y,test_y = cross_validation.train_test_split(train.data,train.target,test_size=0.2,random_state=27)\n",
    "rgf.fit(train_x,train_y)\n",
    "predict_prob_y = rgf.predict_proba(test_x)\n",
    "test_auc = metrics.roc_auc_score(test_y,predict_prob_y[:,1])\n",
    "print (test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
